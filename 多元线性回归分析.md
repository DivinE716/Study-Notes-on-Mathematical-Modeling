# 多元线性回归分析
## 1. 算法背景及概念
多元线性回归的基本形式为：

$$Y=\beta_0+\beta_1x_1+\beta_2x_2+\dots+\beta_nx_n+\varepsilon$$

其中：
- $\varepsilon$：误差项
- $\beta_i$：回归系数（各变量的影响程度）
- $\beta_0$：截距
- $x_i$：自变量（影响因素）
- $Y$：因变量（待预测的值）

---

相比于一元线性回归，二者的原理差异如下：
| 线性回归 | 一元线性回归 | 多元线性回归 |
|:-------:|:----------:|:----------:|
| 模型举例 | $y = 6.6 + 0.8x$ | $y = 6.6 + 0.5x_1 + 0.1x_2 + 0.3x_3$ |
| 自变量 | 仅一个自变量 | 多个自变量 |
| 自变量选择 | 强迫选择，只有一个 | 逐步筛选(特征工程) |
| 共线性 | 无 | 自变量之间要求无多重共线性影响 |
| 回归系数 | 回归系数 | 偏回归系数 |
| 模型评价 | $R^2$ | 调整后的$R^2$ |
| 应用范围 | 一般作为中间分析过程 | 更广泛、用作变量关系研究的依据 |

## 2. 模型检验与评价
拟合线性回归模型后，要对模型总体拟合状况进行检验和评价，通过检验后方可用于影响因素分析或回归预测。线性回归模型的检验如下：

**（1）回归方程总体显著性检验：F检验**
采用F检验对回归模型总体是否显著(有统计学意义)进行检验。该检验原假设回归方程中至少有一个自变量的回归系数不为0，当F检验的p值小于0.05时说明模型显著，即至少有一个自变量对因变量的影响有统计学意义；反之，若p值大于0.05则说明模型不成立。

**（2）回归系数显著性检验：t检验**
回归方程总体显著，如果想进一步判断哪些自变量的回归系数是显著的，则需要进行t检验。如果回归系数t检验p值<0.05，则说明该变量回归系数不为0，其对因变量有显著影响；反之，若p值>0.05，则说明该自变量的回归系数为0，自变量的影响无统计学意义。

**（3）回归方程拟合优度评价：$R^2$**
拟合优度是指样本数据各点围绕回归直线的密集程度，用来评价回归模型的拟合质量。一般是用决定系数$R^2$为评价指标， $R^2$  接近1说明回归模型拟合优度良好，$R^2$接近0说明回归模型拟合优度差。$R^2$的表达式为：

$$R^2=1-\frac{\{SSE\}}{\{SST\}}=1-\frac{\sum(y_i-\hat{y_i})^2}{\sum (y_i - \bar{y})^2}$$

其中：
- $SSE$：残差平方和
- $SST$：总平方和
- $\hat{y_i}$：预测值
- $\bar{y}$：实际值的平均值

## 3. 线性回归模型基本步骤
![模型框架](https://pic2.zhimg.com/v2-8cf9fbc1e53775e6c9b0da9b60ccb425_r.jpg)
实际上，进行多元线性回归分析建模时，最重要的步骤就是**特征选择**。只要成功从海量的特征中筛选出关键因素，那么该问题就解决一大半了。
多元线性回归中特征筛选的核心是从候选特征中选出对目标变量解释力强、无冗余的最优子集，主要流程分为**数据预处理、初步筛选、子集筛选、模型评估、最终确定**五步。

### 3.1 数据预处理：为筛选打基础
此阶段旨在清理数据、统一特征格式，避免原始数据问题影响筛选结果。 
- 处理数据缺陷：填补或删除缺失值，识别并处理异常值（如通过箱线图、Z-score法）。
- 特征类型转换：对分类变量进行编码（如One-Hot编码、标签编码），确保所有特征为数值型。
- 初步共线性检查：通过**方差膨胀因子（VIF）** 或相关系数矩阵，初步识别严重共线性特征（VIF>10通常视为共线性较强）。 

### 3.2 初步筛选：剔除无效特征
快速排除对目标变量几乎无影响的特征，减少后续筛选的计算量。 
- 方差筛选：删除方差极小的特征（如某特征90%以上值相同），这类特征无区分度，对模型无贡献。 
- 单变量相关性筛选：计算特征与目标变量的**皮尔逊相关系数**，剔除相关系数绝对值小于阈值（如0.1）的特征。 
- 单变量显著性检验：对每个特征单独构建简单线性回归，通过**t检验**或**F检验**，剔除p值大于显著性水平（如0.05）的特征。 

### 3.3 核心子集筛选：确定候选特征组合 
从初步筛选后的特征中，通过特定策略选择“最优子集”，常用方法分为两类： 
| 筛选方法 | 核心逻辑 | 
|:--------:|---------| 
| 向前选择 | 从无特征开始，每次加入对模型提升最显著的特征，直到无显著特征可加。 | 
| 向后消除 | 从全特征开始，每次删除对模型影响最小的特征，直到删除后模型性能下降。 | 
| 逐步回归 | 结合向前与向后，每次加入特征后检查是否有冗余特征需删除，双向优化。 | 
| 最优子集选择 | 遍历所有可能的特征子集，选择评估指标最优的子集（仅适用于特征数量少的场景）。 | 

### 3.4 模型评估与验证：判断子集优劣 
通过量化指标评估不同候选子集的性能，避免过拟合。 关键评估指标： 
1. **调整R²**：相比R²，能惩罚过多无关特征，调整R²越高说明模型解释力越强且特征冗余少。 
2. **AIC（赤池信息准则）/BIC（贝叶斯信息准则）**：同时考虑拟合度与特征数量，值越小的模型越优（BIC对特征数量的惩罚更严格）。 

交叉验证：使用K折交叉验证（如5折、10折），验证候选子集在不同数据分区上的稳定性，避免单一训练集的偏差。
### 3.5 最终验证与确定：锁定最优特征集
对评估出的“最优子集”做最后检查，确保符合多元线性回归的基本假设。 
- 残差分析：验证残差是否满足**正态性、方差齐性（homoscedasticity）、独立性**，若假设不满足，需回溯调整特征（如删除异常值、转换特征）。 
- 再次检查共线性：用VIF确认最终子集内无严重共线性特征，确保模型系数估计稳定。 
- 确定最终特征：通过上述验证后，即可确定用于最终多元线性回归模型的特征集。
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTM5NDU2NzcwOV19
-->